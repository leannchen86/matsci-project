# StackOverBond

An independent audit of Google DeepMind's [GNoME](https://www.nature.com/articles/s41586-023-06735-9) crystal structure predictions using classical chemistry rules — presented in a Stack Overflow-inspired interface.

GNoME predicted ~520k materials using graph neural networks trained on DFT data. We apply **textbook chemistry checks completely independent of the DFT/ML pipeline** to 3,262 ternary oxygen-containing compounds, then let Claude ask research questions about the results.

## Quick Start

```bash
cd materials_discovery
python3 -m http.server 8080 --directory interface
```

Open `http://localhost:8080` in your browser. Everything is pre-built — no install needed to browse.

## Install (if regenerating data)

```bash
cd materials_discovery
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

## What You're Looking At

Each material is a "question" in SO style. The **confidence anatomy bar** (replacing SO's vote count) shows how it scored across 6 validators:

| Validator | What it checks | Tier |
|-----------|---------------|------|
| Charge Neutrality | Oxidation states sum to zero | 1 (DFT-independent) |
| Shannon Radii | Bond lengths match expected ionic radii | 1 |
| Pauling Rule 2 | Electrostatic valence around O sites | 1 |
| Goldschmidt | Perovskite tolerance factor | 1 |
| Bond Valence Sum (GII) | Global bond strain | 2 (uses DFT geometry) |
| Space Group | Matches experimental databases | 2 |

**"Claude asks"** — 1,700 materials have a research question generated by Claude, using cross-material family context (sibling compounds in the same chemical system). These are hypotheses, not judgments.

## Exploring the Data

- **Search** by formula, element, or material ID
- **Sort** by any column — try GII score to find the most strained predictions
- **Filter** by compound class, crystal system, or MP match type
- **Interesting Failures** (sidebar) — algorithmically detected anomalies:
  - *Tier conflict*: all Tier 1 checks pass, Tier 2 fails dramatically
  - *Suspiciously perfect*: novel material aces every check
  - *Identity crisis*: oxidation state methods disagree
  - *Geometric strain*: charge-neutral but extreme bond strain
- **Expand** any row to see full validation details, worst-site BVS breakdown, and space group comparison

## Key Findings

- 74.3% of predictions are truly novel (no match in Materials Project)
- 18% are mixed-anion compounds (oxyhalides, oxychalcogenides) where the O2- assumption may not hold
- Novel predictions are statistically indistinguishable from computationally known materials across all validators (positive signal for GNoME)
- BVS "failures" primarily reflect the expected offset between DFT-relaxed and experimental geometries

## Project Structure

```
materials_discovery/
  interface/
    index.html              # StackOverBond frontend
    data.js                 # All 3,262 materials + validation results (13 MB)
  gnome_auditor/
    cli.py                  # CLI: python -m gnome_auditor.cli {stats,validate,...}
    pipeline.py             # Validation pipeline orchestration
    export_data.py          # SQLite -> data.js
    opus_questions.py       # Question generation docs + prompt
    analysis.py             # Calibration plots
    validators/             # 6 validators + oxi state assignment
    db/                     # SQLite schema + queries
    data/                   # Ingestion + MP cross-referencing
    gold_data/              # Synth/not-synth reference CSVs (ICSD)
  data/
    opus_questions.json     # 1,700 Claude research questions
```

## Regenerating

If you have the SQLite database (`data/auditor_db/gnome_auditor.db`):

```bash
source .venv/bin/activate
python -m gnome_auditor.export_data      # Regenerate data.js
python -m gnome_auditor.cli stats        # View pipeline results
python -m gnome_auditor.analysis         # Generate calibration plots
```

## License

Apache 2.0 (code). GNoME data under CC BY-NC 4.0 per [Google's terms](https://creativecommons.org/licenses/by-nc/4.0/).

Built for the Anthropic Claude Code Hackathon, Feb 2025.
